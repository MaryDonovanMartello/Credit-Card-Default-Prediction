{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Prediction with Imbalanced Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mary Donovan Martello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Test Different Subsets of Input Features for Optimizing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import argmax\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#stop unnecessary warnings from printing to the screen\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a dataframe\n",
    "\n",
    "df = pd.read_csv('pcaDefault.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Dataframe for Probability Predictions and Classifier Threshold**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Dataframe for Testing Feature Subsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEX  EDUCATION  MARRIAGE\n",
      "0    1          1         2\n",
      "1    1          2         2\n",
      "2    1          1         1\n",
      "3    2          2         2\n"
     ]
    }
   ],
   "source": [
    "# use only to create subsets\n",
    "\n",
    "# convert categorical data to numbers \n",
    "#get the categorical data\n",
    "cat_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "df_cat = df[cat_features]\n",
    "\n",
    "# create dummy variable dataframe for categorical values \n",
    "dfDumm = pd.get_dummies(df_cat)\n",
    "\n",
    "# check the data\n",
    "print(dfDumm.head(4))\n",
    "\n",
    "# create a whole features dataset that can be used for train and validation data splitting\n",
    "# combine the numerical features and the dummie features together\n",
    "dfNum = df.drop(['SEX', 'EDUCATION', 'MARRIAGE', 'default'], axis = 1)\n",
    "X = pd.concat([dfNum, dfDumm], axis=1)\n",
    "# create a whole target dataset that can be used for train and validation data splitting\n",
    "y =  df['default']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the input features for testing feature subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'SEX',\n",
       "       'EDUCATION', 'MARRIAGE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test different subsets of input features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.79\n"
     ]
    }
   ],
   "source": [
    "# baseline of all variables\n",
    "fullset = X.loc[:, [\n",
    " 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'SEX',\n",
    "       'EDUCATION', 'MARRIAGE']]\n",
    "\n",
    "# separate data into training and validation \n",
    "FTrain, FTest, yTrain_F, yTest_F = train_test_split(fullset, y, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRF = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRF.fit(FTrain, yTrain_F)\n",
    "\n",
    "# predict on test set\n",
    "yhatF = modelLRF.predict(FTest)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_F, yhatF)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.90\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# lR top 5 important features\n",
    "subset1 = X.loc[:, [\n",
    " 'PC7',\n",
    " 'PC1',\n",
    " 'PC8',\n",
    " 'MARRIAGE'   \n",
    " 'PC2',\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S1Train, S1Test, yTrain_S1, yTest_S1 = train_test_split(subset1, y, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS1 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS1.fit(S1Train, yTrain_S1)\n",
    "\n",
    "# predict on test set\n",
    "yhatS1 = modelLRS1.predict(S1Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S1, yhatS1)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.83\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# LR top 6 important features\n",
    "subset2 = X.loc[:, [\n",
    " 'PC7',\n",
    " 'PC1',\n",
    " 'PC8',\n",
    " 'MARRIAGE',   \n",
    " 'PC2',\n",
    " 'SEX',\n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S2Train, S2Test, yTrain_S2, yTest_S2 = train_test_split(subset2, y, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS2 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS2.fit(S2Train, yTrain_S2)\n",
    "\n",
    "# predict on test set\n",
    "yhatS2 = modelLRS2.predict(S2Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S2, yhatS2)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.96\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# CART DecisionTreeClassifier \n",
    "# TOP 6 important features\n",
    "subset3 = X.loc[:, [\n",
    " 'PC7',\n",
    " 'PC1',\n",
    " 'PC8',\n",
    "    'PC3',\n",
    "    'PC2',\n",
    "    'PC4',\n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S3Train, S3Test, yTrain_S3, yTest_S3 = train_test_split(subset3, y, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS3 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS3.fit(S3Train, yTrain_S3)\n",
    "\n",
    "# predict on test set\n",
    "yhatS3 = modelLRS3.predict(S3Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S3, yhatS3)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.93\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# RandomForestClassifier\n",
    "# TOP 5 important features\n",
    "subset4 = X.loc[:, [\n",
    " 'PC7',\n",
    " 'PC1',\n",
    " 'PC8',\n",
    "  'PC6',\n",
    "    'PC3',  \n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S4Train, S4Test, yTrain_S4, yTest_S4 = train_test_split(subset4, y, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS4 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS4.fit(S4Train, yTrain_S4)\n",
    "\n",
    "# predict on test set\n",
    "yhatS4 = modelLRS4.predict(S4Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S4, yhatS4)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.96\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# Ensemble RandomForestClassifier\n",
    "# TOP 6 important features for Default classifier\n",
    "subset5 = X.loc[:, [\n",
    " 'PC7',\n",
    " 'PC1',\n",
    " 'PC8',\n",
    "    'PC3',\n",
    "    'PC2',\n",
    "    'PC4', \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S5Train, S5Test, yTrain_S5, yTest_S5 = train_test_split(subset5, y, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS5 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS5.fit(S5Train, yTrain_S5)\n",
    "\n",
    "# predict on test set\n",
    "yhatS5 = modelLRS5.predict(S5Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S5, yhatS5)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.96\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# XGBClassifier F statisic -combo that produced the highest\n",
    "subset6 = X.loc[:, [\n",
    " 'PC7',\n",
    " 'PC1',\n",
    " 'PC8',\n",
    "    'PC2',\n",
    "    'PC4',\n",
    "     'PC3'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S6Train, S6Test, yTrain_S6, yTest_S6 = train_test_split(subset6, y, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS6 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS6.fit(S6Train, yTrain_S6)\n",
    "\n",
    "# predict on test set\n",
    "yhatS6 = modelLRS6.predict(S6Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S6, yhatS6)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.96\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "\n",
    "# XGBClassifier Scores\n",
    "# Top 8 feature importance minus the Education and Marriage variables\n",
    "subset7 = X.loc[:, [\n",
    " 'PC7',\n",
    " 'PC1',\n",
    " 'PC8',\n",
    "    'PC2',\n",
    "    'PC4',\n",
    "     'PC3'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S7Train, S7Test, yTrain_S7, yTest_S7 = train_test_split(subset7, y, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS7 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS7.fit(S7Train, yTrain_S7)\n",
    "\n",
    "# predict on test set\n",
    "yhatS7 = modelLRS7.predict(S7Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S7, yhatS7)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.84\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# f_classif(X, y)\n",
    "subset8 = X.loc[:, [\n",
    " 'PC7',\n",
    " 'PC1',\n",
    " 'PC8',\n",
    "    'PC2', 'SEX', \n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S8Train, S8Test, yTrain_S8, yTest_S8 = train_test_split(subset8, y, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS8 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS8.fit(S8Train, yTrain_S8)\n",
    "\n",
    "# predict on test set\n",
    "yhatS8 = modelLRS8.predict(S8Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S8, yhatS8)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export best subset df to csv\n",
    "subset7.to_csv('subset7df.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
